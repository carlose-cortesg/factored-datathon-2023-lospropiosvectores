{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a122381b-7163-4a63-96b3-df59286ba955",
   "metadata": {},
   "source": [
    "# Read Syntetic reviews of fashions "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "53c5423e-f16d-439c-8896-0a4fd50a4309",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "reviews = pd.read_csv('../Syntetic_reviews/sample_reviews_fashion.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d896881-cce1-401f-a3e6-b5a1c8eee9d1",
   "metadata": {},
   "source": [
    "# Useful classes and functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a6d487d7-f64a-41f2-887b-9b9cbde3cdee",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def cosine_similarity(v1: np.ndarray, v2: np.ndarray) -> float:\n",
    "    return distance.cosine(v1, v2)\n",
    "\n",
    "class VectorDatabase:\n",
    "    def __init__(self,nlp,model):\n",
    "        self.vectors = {}\n",
    "        self.nlp = nlp\n",
    "        self.model = model\n",
    "        \n",
    "\n",
    "    def split_sentences(self, text):\n",
    "        doc = self.nlp(text, disable=[\"ner\"])\n",
    "        roots = [token  for token in doc if token.dep_ == \"ROOT\" ]\n",
    "    \n",
    "        texts = []\n",
    "        for root in roots:\n",
    "            token_list = [e.i for e in root.subtree]\n",
    "            token_list = list(dict.fromkeys(token_list))\n",
    "            token_list.sort()\n",
    "            text = ' '.join([doc[i].text for i in token_list ])\n",
    "            texts.append(text.lower().strip())\n",
    "            \n",
    "        return texts\n",
    "\n",
    "\n",
    "    def insert(self, sentence: str, polarity: int, type: str) -> None:\n",
    "        model = self.model\n",
    "        embeddings = model.encode(sentence)\n",
    "        key = len(self.vectors) + 1\n",
    "        self.vectors[key] = {'text': sentence,\n",
    "                             'polarity': polarity,\n",
    "                             'type': type,\n",
    "                             'vector': embeddings}\n",
    "\n",
    "    def search(self, query: str):\n",
    "        model = self.model\n",
    "        query_vector = model.encode(query)\n",
    "        \n",
    "        similarities = [(key, value['text'],distance.cosine(query_vector, value['vector']),value['polarity'],value['type']) for key, value in self.vectors.items()]\n",
    "        \n",
    "\n",
    "        aux = pd.DataFrame(similarities)\n",
    "        aux.columns = ['index_db','text','similarity','polarity','topic']\n",
    "\n",
    "        aux = aux.reset_index().query('index<10 or similarity<0.6').query('similarity<0.7')[['index','topic']].groupby(['topic']).count()\n",
    "        \n",
    "        aux['index2'] = aux['index']/aux['index'].sum()\n",
    "        \n",
    "        \n",
    "        \n",
    "        return  list(aux.query('index2>0.4 and index>=4').index.values)\n",
    "\n",
    "    def long_search(self, query: str):\n",
    "        topics = []\n",
    "        for str in self.split_sentences(query):\n",
    "            topics_this = self.search(str)\n",
    "            if len(topics_this)>0:\n",
    "                mini_df = pd.DataFrame(topics_this)\n",
    "                mini_df.columns = ['topic']\n",
    "                mini_df['review'] = query\n",
    "                mini_df['sub_review'] = str\n",
    "                topics.append(mini_df)\n",
    "        if len(topics)>0:\n",
    "            \n",
    "            aux = pd.concat(topics)\n",
    "            #aux ['stars'] = [int(self.sentiment_pipe(str)[0]['label'][0]) for str in aux.sub_review]\n",
    "        else:\n",
    "            aux = None\n",
    "            \n",
    "        return  aux\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71ffc434-3b2f-4a0a-b86b-19a34636a042",
   "metadata": {},
   "source": [
    "# Create V Database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8d7ffcbc-d8b5-4a20-bb37-881ac7f68202",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/factored/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model found at: /Users/mateograciano/.cache/torch/sentence_transformers/sentence-transformers_all-MiniLM-L6-v2/quantized_true.onnx\n",
      "CPU times: user 12.9 s, sys: 1.82 s, total: 14.7 s\n",
      "Wall time: 5.8 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "import numpy as np\n",
    "from scipy.spatial import distance\n",
    "from collections import defaultdict\n",
    "from typing import List, Tuple\n",
    "import spacy\n",
    "\n",
    "from fast_sentence_transformers import FastSentenceTransformer as SentenceTransformer\n",
    "\n",
    "# use any sentence-transformer\n",
    "model = SentenceTransformer(\"all-MiniLM-L6-v2\", device=\"cpu\", quantize=True)\n",
    "\n",
    "\n",
    "nlp = spacy.load(\"en_core_web_lg\")\n",
    "vector_db = VectorDatabase(nlp, model)\n",
    "\n",
    "for index, row in reviews.iterrows():\n",
    "    vector_db.insert(row['Review'],row['Polarity'],row['Topic'])\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2929740b-2501-4579-9398-9cac49d3bcc9",
   "metadata": {},
   "source": [
    "# Download database for casio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "50ffcb27-5bda-4c07-b04d-445fb2dec275",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from google.cloud import bigquery\n",
    "import os\n",
    "\n",
    "os.environ[\"GOOGLE_APPLICATION_CREDENTIALS\"] = \"../sa.json\"\n",
    "\n",
    "\n",
    "client = bigquery.Client()\n",
    "\n",
    "\n",
    "sql = '''\n",
    "SELECT asin, reviewText, overall\n",
    "FROM `factored.raw_reviews`\n",
    "inner join `factored.metadata` using(asin)\n",
    "where brand = 'Casio'\n",
    "'''\n",
    "\n",
    "df = client.query(sql).result().to_dataframe()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "7be58f31-1447-443e-a84d-8de3d326ff8b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 10h 47min 37s, sys: 2min 42s, total: 10h 50min 20s\n",
      "Wall time: 2h 7min 59s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "all_reviews = []\n",
    "for index, row in df.iterrows():\n",
    "    if (row['reviewText'] is not None) & (row['reviewText']!=''):\n",
    "        reviews = vector_db.long_search(row['reviewText'])\n",
    "        if reviews is not None:\n",
    "            reviews = list(reviews.topic.unique())\n",
    "            reviews.append('Overall')\n",
    "            reviews = pd.DataFrame(reviews)\n",
    "            reviews.columns = ['topic']\n",
    "            reviews['score'] = row['overall']\n",
    "            reviews['asin'] = row['asin']\n",
    "            reviews['review'] = row['reviewText']\n",
    "            all_reviews.append(reviews)\n",
    "\n",
    "reviews = pd.concat(all_reviews)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "46f4a522-e3ee-4723-91c9-0f656d863d67",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 204 ms, sys: 41.4 ms, total: 245 ms\n",
      "Wall time: 5.99 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LoadJob<project=plenary-stacker-393921, location=US, id=63eb5adf-8dc6-43bd-a687-886ebe0e1adb>"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "job_config = bigquery.LoadJobConfig(\n",
    "        write_disposition=\"WRITE_TRUNCATE\",\n",
    ")\n",
    "\n",
    "job = client.load_table_from_dataframe(\n",
    "    reviews, 'factored.casio_reviews_by_topic', job_config=job_config\n",
    ")  # Make an API request.\n",
    "\n",
    "job.result()  # Wait for the job to complete."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
