{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a122381b-7163-4a63-96b3-df59286ba955",
   "metadata": {},
   "source": [
    "# Read Syntetic reviews of fashions "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "53c5423e-f16d-439c-8896-0a4fd50a4309",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "reviews = pd.read_csv('../Syntetic_reviews/reviews_all.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71ffc434-3b2f-4a0a-b86b-19a34636a042",
   "metadata": {},
   "source": [
    "# Create V Database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "id": "8d7ffcbc-d8b5-4a20-bb37-881ac7f68202",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model found at: /Users/mateograciano/.cache/torch/sentence_transformers/sentence-transformers_all-MiniLM-L6-v2/quantized_true.onnx\n",
      "Cross validation #1 of 5\n",
      "uploading vectors to DB\n",
      "setting thresholds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<timed exec>:162: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Making Classifications\n",
      "recall: 0.9122807017543859 precision: 0.9122807017543859\n",
      "Cross validation #2 of 5\n",
      "uploading vectors to DB\n",
      "setting thresholds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<timed exec>:162: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Making Classifications\n",
      "recall: 0.9122807017543859 precision: 0.9203539823008849\n",
      "Cross validation #3 of 5\n",
      "uploading vectors to DB\n",
      "setting thresholds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<timed exec>:162: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Making Classifications\n",
      "recall: 0.9649122807017544 precision: 0.9649122807017544\n",
      "Cross validation #4 of 5\n",
      "uploading vectors to DB\n",
      "setting thresholds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<timed exec>:162: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Making Classifications\n",
      "recall: 0.9035087719298246 precision: 0.9035087719298246\n",
      "Cross validation #5 of 5\n",
      "uploading vectors to DB\n",
      "setting thresholds\n",
      "Making Classifications\n",
      "recall: 0.9298245614035088 precision: 0.9380530973451328\n",
      "CPU times: user 11min 5s, sys: 4.58 s, total: 11min 9s\n",
      "Wall time: 4min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<timed exec>:162: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "import numpy as np\n",
    "from scipy.spatial import distance\n",
    "from collections import defaultdict\n",
    "from typing import List, Tuple\n",
    "import spacy\n",
    "from fast_sentence_transformers import FastSentenceTransformer as SentenceTransformer\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "class VectorDatabase:\n",
    "    def __init__(self,nlp,model):\n",
    "        self.vectors = {}\n",
    "        self.nlp = nlp\n",
    "        self.model = model\n",
    "        self.very_similar = 0.5\n",
    "        self.similar = 0.5\n",
    "        \n",
    "\n",
    "    def split_sentences(self, text):\n",
    "        doc = self.nlp(text, disable=[\"ner\"])\n",
    "        roots = [token  for token in doc if token.dep_ == \"ROOT\" ]\n",
    "    \n",
    "        texts = []\n",
    "        for root in roots:\n",
    "            token_list = [e.i for e in root.subtree]\n",
    "            token_list = list(dict.fromkeys(token_list))\n",
    "            token_list.sort()\n",
    "            text = ' '.join([doc[i].text for i in token_list ])\n",
    "            texts.append(text.lower().strip())\n",
    "            \n",
    "        return texts\n",
    "\n",
    "\n",
    "    def insert(self, sentence: str, polarity: int, type: str) -> None:\n",
    "        model = self.model\n",
    "        embeddings = model.encode(sentence)\n",
    "        key = len(self.vectors) + 1\n",
    "        self.vectors[key] = {'text': sentence,\n",
    "                             'polarity': polarity,\n",
    "                             'type': type,\n",
    "                             'vector': embeddings}\n",
    "\n",
    "    def search(self, query: str):\n",
    "        model = self.model\n",
    "        query_vector = model.encode(query)\n",
    "        \n",
    "        similarities = [(key, value['text'],distance.cosine(query_vector, value['vector']),value['polarity'],value['type']) for key, value in self.vectors.items()]\n",
    "        \n",
    "\n",
    "        aux = pd.DataFrame(similarities)\n",
    "        aux.columns = ['index_db','text','similarity','polarity','topic']\n",
    "        aux = aux.sort_values(by=['similarity']).reset_index(drop=True).reset_index()\n",
    "\n",
    "        #aux = aux.reset_index().query('index<20 or similarity<0.7').query('similarity<1')[['index','topic']].groupby(['topic']).count()\n",
    "        \n",
    "        aux = aux.query('index<=10')\n",
    "        #aux = aux.query('similarity <={}'.format(self.very_similar))\n",
    "\n",
    "        aux = aux.query('similarity <={}'.format(self.similar))\n",
    "        \n",
    "        aux = aux[['index','topic']].groupby(['topic']).count()\n",
    "        \n",
    "        \n",
    "        #aux['index2'] = aux['index']/aux['index'].sum()\n",
    "\n",
    "        \n",
    "        \n",
    "\n",
    "        aux = aux.sort_values(by='index', ascending=False).head(1)\n",
    "                \n",
    "        return  list(aux.index.values)\n",
    "\n",
    "    def long_search(self, query: str):\n",
    "        topics = []\n",
    "        for str in self.split_sentences(query):\n",
    "            topics_this = self.search(str)\n",
    "            if len(topics_this)>0:\n",
    "                mini_df = pd.DataFrame(topics_this)\n",
    "                mini_df.columns = ['topic']\n",
    "                mini_df['review'] = query\n",
    "                mini_df['sub_review'] = str\n",
    "                topics.append(mini_df)\n",
    "        if len(topics)>0:\n",
    "            \n",
    "            aux = pd.concat(topics)\n",
    "            #aux ['stars'] = [int(self.sentiment_pipe(str)[0]['label'][0]) for str in aux.sub_review]\n",
    "        else:\n",
    "            aux = None\n",
    "            \n",
    "        return  aux\n",
    "\n",
    "    def set_th(self):\n",
    "        data = pd.DataFrame(self.vectors).transpose()\n",
    "\n",
    "        same_type_similarity = []\n",
    "        \n",
    "        same_type_top_similarity = []\n",
    "        \n",
    "        for i in range(len(data.vector)):\n",
    "        \n",
    "            vectors = data.vector\n",
    "            vector = vectors.values[i]\n",
    "            aux = pd.DataFrame(\n",
    "                [distance.cosine(vector, vectors[i]) for i in vectors.keys()]\n",
    "            )\n",
    "            \n",
    "            aux.columns = ['similarity']\n",
    "            \n",
    "            aux['topic'] = data.type.values\n",
    "            \n",
    "            topic_review = data.type.values[i]\n",
    "             \n",
    "            same_type_similarity.append(np.percentile(aux.query(f'topic==\"{topic_review}\"').similarity,75))\n",
    "        \n",
    "            same_type_top_similarity.append(np.percentile(aux.query(f'topic==\"{topic_review}\"').similarity,25))\n",
    "        \n",
    "        self.very_similar = np.percentile(same_type_top_similarity,95)\n",
    "        self.similar = np.mean(same_type_similarity)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# use any sentence-transformer\n",
    "model = SentenceTransformer(\"all-MiniLM-L6-v2\", device=\"cpu\", quantize=True)\n",
    "\n",
    "\n",
    "nlp = spacy.load(\"en_core_web_lg\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "for db in range(5):\n",
    "\n",
    "    print(f'Cross validation #{db+1} of 5')\n",
    "    \n",
    "    train_reviews = reviews.sample(n=700)\n",
    "    val_reviews = reviews[~reviews.index.isin(train_reviews.index)]\n",
    "    \n",
    "    vector_db = VectorDatabase(nlp, model)\n",
    "    print('uploading vectors to DB')\n",
    "    for index, row in train_reviews.iterrows():\n",
    "        vector_db.insert(row['Review'],row['Polarity'],row['Topic'])\n",
    "    \n",
    "    print('setting thresholds')\n",
    "    vector_db.set_th()\n",
    "    \n",
    "    \n",
    "    guesses = []\n",
    "    \n",
    "    \n",
    "    for index, row in val_reviews.iterrows():\n",
    "        #print(index)\n",
    "        review = row['Review']\n",
    "        aux = vector_db.long_search(review)\n",
    "        guess = []\n",
    "        if aux is not None:\n",
    "            guess = aux.topic.values\n",
    "        guesses.append(guess)\n",
    "        \n",
    "    val_reviews['guesses'] = guesses\n",
    "    \n",
    "    print('Making Classifications')\n",
    "    recalls = []\n",
    "    precisions= []\n",
    "    for index, row in val_reviews.iterrows():\n",
    "        recall = row['Topic'] in row['guesses']\n",
    "        precision = np.nan\n",
    "        if len(row['guesses'])>0:\n",
    "            precision = recall\n",
    "            \n",
    "        recalls.append(recall)\n",
    "        precisions.append(precision)\n",
    "    \n",
    "    precision = np.nanmean(np.array(precisions))\n",
    "    recall = np.nanmean(np.array(recalls))\n",
    "    \n",
    "    print('recall: {} precision: {}'.format(recall,precision))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "id": "9122c103-1ce5-408c-8e33-af0a87d98994",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model found at: /Users/mateograciano/.cache/torch/sentence_transformers/sentence-transformers_all-MiniLM-L6-v2/quantized_true.onnx\n",
      "uploading vectors to DB\n",
      "setting thresholds\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>topic</th>\n",
       "      <th>review</th>\n",
       "      <th>sub_review</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Design</td>\n",
       "      <td>\\nStylish Timekeeping Elegance with Metallic F...</td>\n",
       "      <td>stylish timekeeping elegance with metallic fla...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Design</td>\n",
       "      <td>\\nStylish Timekeeping Elegance with Metallic F...</td>\n",
       "      <td>i recently acquired this exquisite clock , and...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Material and Quality</td>\n",
       "      <td>\\nStylish Timekeeping Elegance with Metallic F...</td>\n",
       "      <td>the metallic details and choice of materials e...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Material and Quality</td>\n",
       "      <td>\\nStylish Timekeeping Elegance with Metallic F...</td>\n",
       "      <td>now , let 's talk about the material .</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Longevity</td>\n",
       "      <td>\\nStylish Timekeeping Elegance with Metallic F...</td>\n",
       "      <td>the clock 's body is built from high - quality...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Longevity</td>\n",
       "      <td>\\nStylish Timekeeping Elegance with Metallic F...</td>\n",
       "      <td>not only is the clock durable , but it also bo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Design</td>\n",
       "      <td>\\nStylish Timekeeping Elegance with Metallic F...</td>\n",
       "      <td>it 's a statement piece that effortlessly comp...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Design</td>\n",
       "      <td>\\nStylish Timekeeping Elegance with Metallic F...</td>\n",
       "      <td>its impeccable craftsmanship and striking appe...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  topic                                             review  \\\n",
       "0                Design  \\nStylish Timekeeping Elegance with Metallic F...   \n",
       "0                Design  \\nStylish Timekeeping Elegance with Metallic F...   \n",
       "0  Material and Quality  \\nStylish Timekeeping Elegance with Metallic F...   \n",
       "0  Material and Quality  \\nStylish Timekeeping Elegance with Metallic F...   \n",
       "0             Longevity  \\nStylish Timekeeping Elegance with Metallic F...   \n",
       "0             Longevity  \\nStylish Timekeeping Elegance with Metallic F...   \n",
       "0                Design  \\nStylish Timekeeping Elegance with Metallic F...   \n",
       "0                Design  \\nStylish Timekeeping Elegance with Metallic F...   \n",
       "\n",
       "                                          sub_review  \n",
       "0  stylish timekeeping elegance with metallic fla...  \n",
       "0  i recently acquired this exquisite clock , and...  \n",
       "0  the metallic details and choice of materials e...  \n",
       "0             now , let 's talk about the material .  \n",
       "0  the clock 's body is built from high - quality...  \n",
       "0  not only is the clock durable , but it also bo...  \n",
       "0  it 's a statement piece that effortlessly comp...  \n",
       "0  its impeccable craftsmanship and striking appe...  "
      ]
     },
     "execution_count": 244,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "from scipy.spatial import distance\n",
    "from collections import defaultdict\n",
    "from typing import List, Tuple\n",
    "import spacy\n",
    "from fast_sentence_transformers import FastSentenceTransformer as SentenceTransformer\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "class VectorDatabase:\n",
    "    def __init__(self,nlp,model):\n",
    "        self.vectors = {}\n",
    "        self.nlp = nlp\n",
    "        self.model = model\n",
    "        self.very_similar = 0.5\n",
    "        self.similar = 0.5\n",
    "        \n",
    "\n",
    "    def split_sentences(self, text):\n",
    "        doc = self.nlp(text, disable=[\"ner\"])\n",
    "        roots = [token  for token in doc if token.dep_ == \"ROOT\" ]\n",
    "    \n",
    "        texts = []\n",
    "        for root in roots:\n",
    "            token_list = [e.i for e in root.subtree]\n",
    "            token_list = list(dict.fromkeys(token_list))\n",
    "            token_list.sort()\n",
    "            text = ' '.join([doc[i].text for i in token_list ])\n",
    "            texts.append(text.lower().strip())\n",
    "            \n",
    "        return texts\n",
    "\n",
    "\n",
    "    def insert(self, sentence: str, polarity: int, type: str) -> None:\n",
    "        model = self.model\n",
    "        embeddings = model.encode(sentence)\n",
    "        key = len(self.vectors) + 1\n",
    "        self.vectors[key] = {'text': sentence,\n",
    "                             'polarity': polarity,\n",
    "                             'type': type,\n",
    "                             'vector': embeddings}\n",
    "\n",
    "    def search(self, query: str):\n",
    "        model = self.model\n",
    "        query_vector = model.encode(query)\n",
    "        \n",
    "        similarities = [(key, value['text'],distance.cosine(query_vector, value['vector']),value['polarity'],value['type']) for key, value in self.vectors.items()]\n",
    "        \n",
    "\n",
    "        aux = pd.DataFrame(similarities)\n",
    "        aux.columns = ['index_db','text','similarity','polarity','topic']\n",
    "        aux = aux.sort_values(by=['similarity']).reset_index(drop=True).reset_index()\n",
    "\n",
    "        #aux = aux.reset_index().query('index<20 or similarity<0.7').query('similarity<1')[['index','topic']].groupby(['topic']).count()\n",
    "        \n",
    "        aux = aux.query('index<=10')\n",
    "        #aux = aux.query('similarity <={}'.format(self.very_similar))\n",
    "\n",
    "        aux = aux.query('similarity <={}'.format(self.similar))\n",
    "        \n",
    "        aux = aux[['index','topic']].groupby(['topic']).count()\n",
    "        \n",
    "        \n",
    "        #aux['index2'] = aux['index']/aux['index'].sum()\n",
    "\n",
    "        \n",
    "        \n",
    "\n",
    "        aux = aux.sort_values(by='index', ascending=False).head(1)\n",
    "                \n",
    "        return  list(aux.index.unique())\n",
    "\n",
    "    def long_search(self, query: str):\n",
    "        topics = []\n",
    "        for str in self.split_sentences(query):\n",
    "            topics_this = self.search(str)\n",
    "            if len(topics_this)>0:\n",
    "                mini_df = pd.DataFrame(topics_this)\n",
    "                mini_df.columns = ['topic']\n",
    "                mini_df['review'] = query\n",
    "                mini_df['sub_review'] = str\n",
    "                topics.append(mini_df)\n",
    "        if len(topics)>0:\n",
    "            \n",
    "            aux = pd.concat(topics)\n",
    "            #aux ['stars'] = [int(self.sentiment_pipe(str)[0]['label'][0]) for str in aux.sub_review]\n",
    "        else:\n",
    "            aux = None\n",
    "            \n",
    "        return  aux\n",
    "\n",
    "    def set_th(self):\n",
    "        data = pd.DataFrame(self.vectors).transpose()\n",
    "\n",
    "        same_type_similarity = []\n",
    "        \n",
    "        same_type_top_similarity = []\n",
    "        \n",
    "        for i in range(len(data.vector)):\n",
    "        \n",
    "            vectors = data.vector\n",
    "            vector = vectors.values[i]\n",
    "            aux = pd.DataFrame(\n",
    "                [distance.cosine(vector, vectors[i]) for i in vectors.keys()]\n",
    "            )\n",
    "            \n",
    "            aux.columns = ['similarity']\n",
    "            \n",
    "            aux['topic'] = data.type.values\n",
    "            \n",
    "            topic_review = data.type.values[i]\n",
    "             \n",
    "            same_type_similarity.append(np.percentile(aux.query(f'topic==\"{topic_review}\"').similarity,75))\n",
    "        \n",
    "            same_type_top_similarity.append(np.percentile(aux.query(f'topic==\"{topic_review}\"').similarity,25))\n",
    "        \n",
    "        self.very_similar = np.mean(same_type_top_similarity)\n",
    "        self.similar = np.mean(same_type_similarity)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# use any sentence-transformer\n",
    "model = SentenceTransformer(\"all-MiniLM-L6-v2\", device=\"cpu\", quantize=True)\n",
    "\n",
    "\n",
    "nlp = spacy.load(\"en_core_web_lg\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "vector_db = VectorDatabase(nlp, model)\n",
    "print('uploading vectors to DB')\n",
    "for index, row in reviews.iterrows():\n",
    "    vector_db.insert(row['Review'],row['Polarity'],row['Topic'])\n",
    "\n",
    "print('setting thresholds')\n",
    "vector_db.set_th()\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "example_review = '''\n",
    "Stylish Timekeeping Elegance with Metallic Flair!\n",
    "\n",
    "I recently acquired this exquisite clock, and I must say, it's a mesmerizing blend of functionality and aesthetics. The metallic details and choice of materials elevate its charm to a whole new level.\n",
    "\n",
    "Let's start with the metallic details - they are nothing short of captivating. The clock's face features intricate metallic accents that catch the light beautifully, adding a touch of elegance and sophistication to any space. It's like having a piece of art adorning your wall, constantly drawing your gaze with its shimmering allure.\n",
    "\n",
    "The metallic elements aren't just for show; they also serve a functional purpose. The minute and hour hands, crafted with a sleek metallic finish, provide a clear contrast against the clock's background, ensuring effortless readability even from a distance. There's no squinting or straining your eyes to tell the time; it's like having a timekeeper tailor-made for convenience.\n",
    "\n",
    "Now, let's talk about the material. The clock's body is built from high-quality materials that exude a sense of sturdiness and durability. The frame, carefully crafted with a combination of premium metals and other robust elements, feels solid to the touch, instilling confidence in its long-lasting performance.\n",
    "\n",
    "Not only is the clock durable, but it also boasts a luxurious feel. The metallic accents extend to the edges of the frame, creating a seamless and refined finish that adds a touch of opulence to any room. It's a statement piece that effortlessly complements both modern and classic d√©cor.\n",
    "\n",
    "The attention to detail in this clock is truly commendable. From the precise cut of the metallic elements to the careful assembly, it's evident that the manufacturers poured their passion into creating a timepiece that stands out in both form and function.\n",
    "\n",
    "In conclusion, this clock is a stunning blend of metallic details and high-quality materials, marrying elegance with functionality flawlessly. Whether you're looking to add a touch of sophistication to your home or seeking a reliable timekeeping companion, this clock exceeds expectations on every front. Its impeccable craftsmanship and striking appearance make it a valuable addition to any space, destined to garner admiration from anyone who sets their eyes on it.\n",
    "\n",
    "'''\n",
    "\n",
    "\n",
    "vector_db.long_search(example_review)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "id": "b4767683-8eff-47a1-999a-31482e013664",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>topic</th>\n",
       "      <th>review</th>\n",
       "      <th>sub_review</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Fit and Comfort</td>\n",
       "      <td>\\nbought these shoes for my girlfriend .\\n</td>\n",
       "      <td>bought these shoes for my girlfriend .</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             topic                                      review  \\\n",
       "0  Fit and Comfort  \\nbought these shoes for my girlfriend .\\n   \n",
       "\n",
       "                               sub_review  \n",
       "0  bought these shoes for my girlfriend .  "
      ]
     },
     "execution_count": 276,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "example_review = '''\n",
    "bought these shoes for my girlfriend .\n",
    "'''\n",
    "\n",
    "\n",
    "topics_details = vector_db.long_search(example_review)\n",
    "\n",
    "topics_details\n",
    "\n",
    "#topics_details.to_csv('example_details.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "id": "5e8f7906-5b12-40d4-ac80-4bf33dfc15bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.cloud import bigquery\n",
    "import os\n",
    "\n",
    "os.environ[\"GOOGLE_APPLICATION_CREDENTIALS\"] = \"../sa.json\"\n",
    "\n",
    "\n",
    "client = bigquery.Client()\n",
    "\n",
    "\n",
    "sql = '''\n",
    "\n",
    "SELECT reviewText,overall,asin\n",
    "from `factored.raw_reviews`\n",
    "WHERE asin = 'B00HDZIT0S'\n",
    "'''\n",
    "\n",
    "df = client.query(sql).result().to_dataframe()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "id": "f03e632e-a994-4e45-a60c-740628d28286",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>topic</th>\n",
       "      <th>review</th>\n",
       "      <th>sub_review</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Fit and Comfort</td>\n",
       "      <td>Bought these shoes for my girlfriend. She said...</td>\n",
       "      <td>bought these shoes for my girlfriend .</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             topic                                             review  \\\n",
       "0  Fit and Comfort  Bought these shoes for my girlfriend. She said...   \n",
       "\n",
       "                               sub_review  \n",
       "0  bought these shoes for my girlfriend .  "
      ]
     },
     "execution_count": 273,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vector_db.long_search(review)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "id": "d382d235-85bc-42f9-8d44-7cc06a3418ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n",
      "22\n",
      "23\n",
      "24\n",
      "25\n",
      "26\n",
      "27\n",
      "28\n",
      "29\n",
      "30\n",
      "31\n",
      "32\n",
      "33\n",
      "34\n",
      "35\n",
      "36\n",
      "37\n",
      "38\n",
      "39\n",
      "40\n",
      "41\n",
      "42\n",
      "43\n",
      "44\n",
      "45\n",
      "46\n",
      "47\n",
      "48\n",
      "49\n",
      "50\n",
      "51\n",
      "52\n",
      "53\n",
      "54\n",
      "55\n",
      "56\n",
      "57\n",
      "58\n",
      "59\n",
      "60\n",
      "61\n",
      "62\n",
      "63\n",
      "64\n",
      "65\n",
      "66\n",
      "67\n",
      "68\n",
      "69\n",
      "70\n",
      "71\n",
      "72\n",
      "73\n",
      "74\n",
      "75\n",
      "76\n",
      "77\n",
      "78\n",
      "79\n",
      "80\n",
      "81\n",
      "82\n",
      "83\n",
      "84\n",
      "85\n",
      "86\n",
      "87\n",
      "88\n",
      "89\n",
      "90\n",
      "91\n",
      "92\n",
      "93\n",
      "94\n",
      "95\n",
      "96\n",
      "97\n",
      "98\n",
      "99\n",
      "100\n",
      "101\n",
      "102\n",
      "103\n",
      "104\n",
      "105\n",
      "106\n",
      "107\n",
      "108\n",
      "109\n",
      "110\n",
      "111\n",
      "112\n",
      "113\n",
      "114\n",
      "115\n",
      "116\n",
      "117\n",
      "118\n",
      "119\n",
      "120\n",
      "121\n",
      "122\n",
      "123\n",
      "124\n",
      "125\n",
      "126\n",
      "127\n",
      "128\n",
      "129\n",
      "130\n",
      "131\n",
      "132\n",
      "133\n",
      "134\n",
      "135\n",
      "136\n",
      "137\n",
      "138\n",
      "139\n",
      "140\n",
      "141\n",
      "142\n",
      "143\n",
      "144\n",
      "145\n",
      "146\n",
      "147\n",
      "148\n",
      "149\n",
      "150\n",
      "151\n",
      "152\n",
      "153\n",
      "154\n",
      "155\n",
      "156\n",
      "157\n",
      "158\n",
      "159\n",
      "160\n",
      "161\n",
      "162\n",
      "163\n",
      "164\n",
      "165\n",
      "166\n",
      "167\n",
      "168\n",
      "169\n",
      "170\n",
      "171\n",
      "172\n",
      "173\n",
      "174\n",
      "175\n",
      "176\n",
      "177\n",
      "178\n",
      "179\n",
      "180\n",
      "181\n",
      "182\n",
      "183\n",
      "184\n",
      "185\n",
      "186\n",
      "187\n",
      "188\n",
      "189\n",
      "190\n",
      "191\n",
      "192\n",
      "193\n",
      "194\n",
      "195\n",
      "196\n",
      "197\n",
      "198\n",
      "199\n",
      "200\n",
      "201\n",
      "202\n",
      "203\n",
      "204\n",
      "205\n",
      "206\n",
      "207\n",
      "208\n",
      "209\n",
      "210\n",
      "211\n",
      "212\n",
      "213\n",
      "214\n",
      "215\n",
      "216\n",
      "217\n",
      "218\n",
      "219\n",
      "220\n",
      "221\n",
      "222\n",
      "223\n",
      "224\n",
      "225\n",
      "226\n",
      "227\n",
      "228\n",
      "229\n",
      "230\n",
      "231\n",
      "232\n",
      "233\n",
      "234\n",
      "235\n",
      "236\n",
      "237\n",
      "238\n",
      "239\n",
      "240\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>stars</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>topic</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>overall</th>\n",
       "      <td>3.809129</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Customer Support</th>\n",
       "      <td>3.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Design</th>\n",
       "      <td>4.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Fit and Comfort</th>\n",
       "      <td>3.964286</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Longevity</th>\n",
       "      <td>3.200000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Material and Quality</th>\n",
       "      <td>3.600000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Packaging and Presentation</th>\n",
       "      <td>4.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Price and Value</th>\n",
       "      <td>3.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>User Experience</th>\n",
       "      <td>4.166667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Versatility</th>\n",
       "      <td>3.500000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                               stars\n",
       "topic                               \n",
       "overall                     3.809129\n",
       "Customer Support            3.000000\n",
       "Design                      4.666667\n",
       "Fit and Comfort             3.964286\n",
       "Longevity                   3.200000\n",
       "Material and Quality        3.600000\n",
       "Packaging and Presentation  4.000000\n",
       "Price and Value             3.500000\n",
       "User Experience             4.166667\n",
       "Versatility                 3.500000"
      ]
     },
     "execution_count": 278,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ans= []\n",
    "for index, row in df.iterrows():\n",
    "    print(index)\n",
    "    review = row['reviewText']\n",
    "    if review is None:\n",
    "        review = ''\n",
    "    if (len(review)>0):\n",
    "        aux = vector_db.long_search(review)\n",
    "        if aux is not None:\n",
    "            aux['stars'] = row['overall']\n",
    "            ans.append(aux)\n",
    "            #print(review,ans)\n",
    "\n",
    "ans = pd.concat(ans)\n",
    "\n",
    "\n",
    "df['topic']= 'overall'\n",
    "overall = df[['topic','overall']].groupby(['topic']).mean()\n",
    "overall.columns = ['stars']\n",
    "\n",
    "\n",
    "topics = ans[['topic','stars']].groupby(['topic']).mean()\n",
    "\n",
    "\n",
    "pd.concat([overall,topics])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
