{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a122381b-7163-4a63-96b3-df59286ba955",
   "metadata": {},
   "source": [
    "# Read Syntetic reviews of fashions "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "53c5423e-f16d-439c-8896-0a4fd50a4309",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "reviews = pd.read_csv('../Syntetic_reviews/sample_reviews_fashion.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d896881-cce1-401f-a3e6-b5a1c8eee9d1",
   "metadata": {},
   "source": [
    "# Useful classes and functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "a6d487d7-f64a-41f2-887b-9b9cbde3cdee",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def cosine_similarity(v1: np.ndarray, v2: np.ndarray) -> float:\n",
    "    return distance.cosine(v1, v2)\n",
    "\n",
    "class VectorDatabase:\n",
    "    def __init__(self,nlp,model):\n",
    "        self.vectors = {}\n",
    "        self.nlp = nlp\n",
    "        self.model = model\n",
    "        \n",
    "\n",
    "    def split_sentences(self, text):\n",
    "        doc = self.nlp(text, disable=[\"ner\"])\n",
    "        roots = [token  for token in doc if token.dep_ == \"ROOT\" ]\n",
    "    \n",
    "        texts = []\n",
    "        for root in roots:\n",
    "            token_list = [e.i for e in root.subtree]\n",
    "            token_list = list(dict.fromkeys(token_list))\n",
    "            token_list.sort()\n",
    "            text = ' '.join([doc[i].text for i in token_list ])\n",
    "            texts.append(text.lower().strip())\n",
    "            \n",
    "        return texts\n",
    "\n",
    "\n",
    "    def insert(self, sentence: str, polarity: int, type: str) -> None:\n",
    "        model = self.model\n",
    "        embeddings = list(model.encode([sentence])[0])\n",
    "        key = len(self.vectors) + 1\n",
    "        self.vectors[key] = {'text': sentence,\n",
    "                             'polarity': polarity,\n",
    "                             'type': type,\n",
    "                             'vector': embeddings}\n",
    "\n",
    "    def search(self, query: str):\n",
    "        model = self.model\n",
    "        query_vector = list(model.encode([query])[0])\n",
    "        \n",
    "        similarities = [(key, value['text'],distance.cosine(query_vector, value['vector']),value['polarity'],value['type']) for key, value in self.vectors.items()]\n",
    "        \n",
    "\n",
    "        aux = pd.DataFrame(similarities)\n",
    "        aux.columns = ['index_db','text','similarity','polarity','topic']\n",
    "\n",
    "        aux = aux.reset_index().query('index<10 or similarity<0.5').query('similarity<0.6')[['index','topic']].groupby(['topic']).count()\n",
    "        \n",
    "        aux['index2'] = aux['index']/aux['index'].sum()\n",
    "        \n",
    "        \n",
    "        \n",
    "        return  list(aux.query('index2>0.4 and index>=4').index.values)\n",
    "\n",
    "    def long_search(self, query: str):\n",
    "        topics = []\n",
    "        for str in self.split_sentences(query):\n",
    "            topics_this = self.search(str)\n",
    "            if len(topics_this)>0:\n",
    "                mini_df = pd.DataFrame(topics_this)\n",
    "                mini_df.columns = ['topic']\n",
    "                mini_df['review'] = query\n",
    "                mini_df['sub_review'] = str\n",
    "                topics.append(mini_df)\n",
    "        if len(topics)>0:\n",
    "            \n",
    "            aux = pd.concat(topics)\n",
    "            #aux ['stars'] = [int(self.sentiment_pipe(str)[0]['label'][0]) for str in aux.sub_review]\n",
    "        else:\n",
    "            aux = None\n",
    "            \n",
    "        return  aux\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71ffc434-3b2f-4a0a-b86b-19a34636a042",
   "metadata": {},
   "source": [
    "# Create V Database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "8d7ffcbc-d8b5-4a20-bb37-881ac7f68202",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.spatial import distance\n",
    "from collections import defaultdict\n",
    "from typing import List, Tuple\n",
    "import spacy\n",
    "from sentence_transformers import SentenceTransformer\n",
    "model = SentenceTransformer('multi-qa-mpnet-base-dot-v1')\n",
    "\n",
    "\n",
    "# Use a pipeline as a high-level helper\n",
    "from transformers import pipeline\n",
    "\n",
    "pipe = pipeline(\"text-classification\", model=\"LiYuan/amazon-review-sentiment-analysis\")\n",
    "\n",
    "\n",
    "nlp = spacy.load(\"en_core_web_lg\")\n",
    "vector_db = VectorDatabase(nlp, model,pipe)\n",
    "\n",
    "for index, row in reviews.iterrows():\n",
    "    vector_db.insert(row['Review'],row['Polarity'],row['Topic'])\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72b804f0-fb16-42b4-85df-11366b34d07b",
   "metadata": {},
   "source": [
    "# Test VDB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "f8c186fe-f4ef-4223-85ae-1f6af1f1b120",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>topic</th>\n",
       "      <th>review</th>\n",
       "      <th>sub_review</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Material and Quality</td>\n",
       "      <td>\\nThese shorts are very flattering and perfect...</td>\n",
       "      <td>i really loved them , until i put them through...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>longevity</td>\n",
       "      <td>\\nThese shorts are very flattering and perfect...</td>\n",
       "      <td>i hung dry them , but the edges have already s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>longevity</td>\n",
       "      <td>\\nThese shorts are very flattering and perfect...</td>\n",
       "      <td>i can tell these shorts will have a short life...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  topic                                             review  \\\n",
       "0  Material and Quality  \\nThese shorts are very flattering and perfect...   \n",
       "0             longevity  \\nThese shorts are very flattering and perfect...   \n",
       "0             longevity  \\nThese shorts are very flattering and perfect...   \n",
       "\n",
       "                                          sub_review  \n",
       "0  i really loved them , until i put them through...  \n",
       "0  i hung dry them , but the edges have already s...  \n",
       "0  i can tell these shorts will have a short life...  "
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "str = '''\n",
    "These shorts are very flattering and perfect for running in. \n",
    "I really loved them, until I put them through the wash once. \n",
    "I hung dry them, but the edges have already started deteriorating. \n",
    "I can tell these shorts will have a short lifespan, and I've never had this type of issue with any other shorts I bought.\n",
    "'''\n",
    "\n",
    "aux = vector_db.long_search(str)\n",
    "\n",
    "aux\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2929740b-2501-4579-9398-9cac49d3bcc9",
   "metadata": {},
   "source": [
    "# Test VDB with some actual reviews from our dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "50ffcb27-5bda-4c07-b04d-445fb2dec275",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from google.cloud import bigquery\n",
    "import os\n",
    "\n",
    "os.environ[\"GOOGLE_APPLICATION_CREDENTIALS\"] = \"../sa.json\"\n",
    "\n",
    "\n",
    "client = bigquery.Client()\n",
    "\n",
    "\n",
    "sql = '''\n",
    "\n",
    "SELECT reviewText,overall,asin\n",
    "from `factored.raw_reviews`\n",
    "WHERE asin = 'B00HDZIT0S'\n",
    "'''\n",
    "\n",
    "df = client.query(sql).result().to_dataframe()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "d314b67a-d011-49c7-8c3e-d6bf2c4e48ea",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n",
      "22\n",
      "23\n",
      "24\n",
      "25\n",
      "26\n",
      "27\n",
      "28\n",
      "29\n",
      "30\n",
      "31\n",
      "32\n",
      "33\n",
      "34\n",
      "35\n",
      "36\n",
      "37\n",
      "38\n",
      "39\n",
      "40\n",
      "41\n",
      "42\n",
      "43\n",
      "44\n",
      "45\n",
      "46\n",
      "47\n",
      "48\n",
      "49\n",
      "50\n",
      "51\n",
      "52\n",
      "53\n",
      "54\n",
      "55\n",
      "56\n",
      "57\n",
      "58\n",
      "59\n",
      "60\n",
      "61\n",
      "62\n",
      "63\n",
      "64\n",
      "65\n",
      "66\n",
      "67\n",
      "68\n",
      "69\n",
      "70\n",
      "71\n",
      "72\n",
      "73\n",
      "74\n",
      "75\n",
      "76\n",
      "77\n",
      "78\n",
      "79\n",
      "80\n",
      "81\n",
      "82\n",
      "83\n",
      "84\n",
      "85\n",
      "86\n",
      "87\n",
      "88\n",
      "89\n",
      "90\n",
      "91\n",
      "92\n",
      "93\n",
      "94\n",
      "95\n",
      "96\n",
      "97\n",
      "98\n",
      "99\n",
      "100\n",
      "101\n",
      "102\n",
      "103\n",
      "104\n",
      "105\n",
      "106\n",
      "107\n",
      "108\n",
      "109\n",
      "110\n",
      "111\n",
      "112\n",
      "113\n",
      "114\n",
      "115\n",
      "116\n",
      "117\n",
      "118\n",
      "119\n",
      "120\n",
      "121\n",
      "122\n",
      "123\n",
      "124\n",
      "125\n",
      "126\n",
      "127\n",
      "128\n",
      "129\n",
      "130\n",
      "131\n",
      "132\n",
      "133\n",
      "134\n",
      "135\n",
      "136\n",
      "137\n",
      "138\n",
      "139\n",
      "140\n",
      "141\n",
      "142\n",
      "143\n",
      "144\n",
      "145\n",
      "146\n",
      "147\n",
      "148\n",
      "149\n",
      "150\n",
      "151\n",
      "152\n",
      "153\n",
      "154\n",
      "155\n",
      "156\n",
      "157\n",
      "158\n",
      "159\n",
      "160\n",
      "161\n",
      "162\n",
      "163\n",
      "164\n",
      "165\n",
      "166\n",
      "167\n",
      "168\n",
      "169\n",
      "170\n",
      "171\n",
      "172\n",
      "173\n",
      "174\n",
      "175\n",
      "176\n",
      "177\n",
      "178\n",
      "179\n",
      "180\n",
      "181\n",
      "182\n",
      "183\n",
      "184\n",
      "185\n",
      "186\n",
      "187\n",
      "188\n",
      "189\n",
      "190\n",
      "191\n",
      "192\n",
      "193\n",
      "194\n",
      "195\n",
      "196\n",
      "197\n",
      "198\n",
      "199\n",
      "200\n",
      "201\n",
      "202\n",
      "203\n",
      "204\n",
      "205\n",
      "206\n",
      "207\n",
      "208\n",
      "209\n",
      "210\n",
      "211\n",
      "212\n",
      "213\n",
      "214\n",
      "215\n",
      "216\n",
      "217\n",
      "218\n",
      "219\n",
      "220\n",
      "221\n",
      "222\n",
      "223\n",
      "224\n",
      "225\n",
      "226\n",
      "227\n",
      "228\n",
      "229\n",
      "230\n",
      "231\n",
      "232\n",
      "233\n",
      "234\n",
      "235\n",
      "236\n",
      "237\n",
      "238\n",
      "239\n",
      "240\n",
      "CPU times: user 1min 45s, sys: 2.77 s, total: 1min 48s\n",
      "Wall time: 1min 48s\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>stars</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>topic</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>overall</th>\n",
       "      <td>3.809129</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Fit and Comfort</th>\n",
       "      <td>3.930769</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Material and Quality</th>\n",
       "      <td>3.808219</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Versatility</th>\n",
       "      <td>4.571429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>longevity</th>\n",
       "      <td>3.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         stars\n",
       "topic                         \n",
       "overall               3.809129\n",
       "Fit and Comfort       3.930769\n",
       "Material and Quality  3.808219\n",
       "Versatility           4.571429\n",
       "longevity             3.000000"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time \n",
    "ans= []\n",
    "for index, row in df.iterrows():\n",
    "    print(index)\n",
    "    review = row['reviewText']\n",
    "    if review is None:\n",
    "        review = ''\n",
    "    if (len(review)>0):\n",
    "        aux = vector_db.long_search(review)\n",
    "        if aux is not None:\n",
    "            aux['stars'] = row['overall']\n",
    "            ans.append(aux)\n",
    "\n",
    "ans = pd.concat(ans)\n",
    "\n",
    "\n",
    "df['topic']= 'overall'\n",
    "overall = df[['topic','overall']].groupby(['topic']).mean()\n",
    "overall.columns = ['stars']\n",
    "\n",
    "\n",
    "topics = ans[['topic','stars']].groupby(['topic']).mean()\n",
    "\n",
    "\n",
    "pd.concat([overall,topics])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "325eca7f-6b8d-4573-abaf-2c1afff0e8dc",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
